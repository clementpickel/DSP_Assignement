{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 - Machine learning and modeling\n",
    "In this assignment, you work in the same groups you already are divided into. You need to define at least one task based on each of the exercises 4, 5 and 10. All together three tasks. You have to apply the tasks on the same dataset that you used in Assignment 1. \n",
    "\n",
    "You will hand in the assignment through a Jupyter notebook, along with your environment and the dataset you picked, both zipped together and submitted as one file. Please name your file so that it contains your group number. It is important that you clearly state the tasks you are performing on the dataset as questions or something similar in the notebook before you do the operations on the data. Also make sure to document your solutions and your thinking so that it can easily be followed. If you fail to do these things, you may not pass this assignment.\n",
    "\n",
    "The deadline of this assignment is on April 26, 2025 to get bonus points, or before the exam (in which case no bonus points will be awarded).\n",
    "\n",
    "Re-submission 1 is by the end of week 33, 2025.\n",
    "\n",
    "Re-submission 2 is by the end of week 2, 2026."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 4\n",
    "The tasks are\n",
    "- Regression\n",
    "- Clustering\n",
    "- Decision Trees and Model validation\n",
    "- SVMs, Hyperparameters, and Cross-Validation\n",
    "\n",
    "# Exercice 5\n",
    "The tasks are:\n",
    "- Permutation feature importance\n",
    "- Statistical testing\n",
    "- Dimensionality reduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from rich import load_ipython_extension\n",
    "    %load_ext rich\n",
    "except ImportError:\n",
    "    try:\n",
    "        from rich import pretty\n",
    "        pretty.install()\n",
    "    except ImportError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../Total air emissions by greenhouse gas.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get x axis, column\n",
    "col = df.columns\n",
    "col = col[2:]\n",
    "x = [int(x) for x in col]\n",
    "print(x)\n",
    "\n",
    "# get y axis, first row value\n",
    "first_row = df.iloc[0].tolist()\n",
    "first_row = first_row[2:]\n",
    "y = [float(x) for x in first_row]\n",
    "print(y)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "x = np.array(x).reshape(-1, 1)\n",
    "y = np.array(y).reshape(-1, 1)\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(x, y)\n",
    "\n",
    "print(\"Coefficient:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n",
    "\n",
    "yfit = model.predict(x)\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit, color='orange', lw=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Polynomial 2 cause i don't think more is needed\n",
    "poly_model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
    "poly_model.fit(x, y)\n",
    "\n",
    "yfit = poly_model.predict(x)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, yfit, color='orange', lw=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get more rows, the first 4\n",
    "def get_row(i):\n",
    "    row = df.iloc[i].tolist()\n",
    "    row = row[2:]                       # remove first 2 col\n",
    "    convert = [float(x) for x in row]   # convert to float\n",
    "    return np.array(convert).reshape(-1, 1)\n",
    "\n",
    "y_0 = get_row(0)\n",
    "y_1 = get_row(1)\n",
    "y_2 = get_row(2)\n",
    "y_3 = get_row(3)\n",
    "\n",
    "plt.scatter(x, y_0, color='red')\n",
    "plt.scatter(x, y_1, color='blue')\n",
    "plt.scatter(x, y_2, color='green')\n",
    "plt.scatter(x, y_3, color='purple')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "for index, y in enumerate([y_0, y_1, y_2, y_3]):\n",
    "    X.append(np.column_stack((x, y)))\n",
    "    Y.extend([index for _ in range(len(y))])\n",
    "\n",
    "X = np.concatenate(X, axis=0)\n",
    "Y = np.array(Y)\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(4, random_state=1)\n",
    "labels = kmeans.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Mixture Model (GMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "\n",
    "gmm = GMM(n_components=4, random_state=0)\n",
    "labels = gmm.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run GMM several times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(n_components=4, n_init=10)\n",
    "labels = gmm.fit(X).predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, s=40, cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it's not very good to get cluster from time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree\n",
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, train_size=0.8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree = DecisionTreeClassifier(random_state=0).fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the decision tree performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "print(\"Absolute error:\", (y_test != y_pred).sum())\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"F1-scores (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1-scores (weighted):\", f1_score(y_test, y_pred, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "mat = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('true label')\n",
    "plt.ylabel('predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it's bigger than i thought so why not reduce it and retest it ? maybe it will be better to generalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Change the max depth to 4, we see on the figure above the depth is 6 with no pre-pruning\n",
    "tree = DecisionTreeClassifier(random_state=0, max_depth=4).fit(X_train, y_train)\n",
    "\n",
    "y_pred = tree.predict(X_test)\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "print(\"Absolute error:\", (y_test != y_pred).sum())\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(\"F1-scores (macro):\", f1_score(y_test, y_pred, average='macro'))\n",
    "print(\"F1-scores (weighted):\", f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plot_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope, reducing the max depth doesn't improve the performance in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 5 \n",
    "## Permutation feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### importing again, to be clear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "df = pd.read_csv(\"../Total air emissions by greenhouse gas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cleaning data, remplacing NaN per the mean for each columns, for more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "years = [str(year) for year in range(1990, 2024)]\n",
    "for year in years:\n",
    "    df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "\n",
    "df[years] = df[years].fillna(df[years].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### created a new target : did the consumption grow or not between 2023 and 1990 ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['growth'] = df['2023'] - df['1990']\n",
    "df['target'] = (df['growth'] > 0).astype(int)  # 1 is true, 0 is false\n",
    "\n",
    "X = df[years]\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Shape X: {X.shape}\")\n",
    "print(f\"Shape y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting, creating the model for trying to predict the growth, training, getting the accuracy score and the importance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "\n",
    "# Modèle\n",
    "model = SVC(C=1.0, gamma=0.0001, kernel=\"rbf\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Score\n",
    "print(f\"Accuracy : {accuracy_score(y_pred, y_test):.4f}\")\n",
    "\n",
    "# Permutation importance\n",
    "pi = permutation_importance(model, X_test, y_test, n_repeats=50, random_state=0)\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': pi['importances_mean']})\n",
    "importances = importances.sort_values(by='importance', ascending=False)\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the most important feature\n",
    "most_important_feature = importances.iloc[0]\n",
    "print(f\"The most important feature is: {most_important_feature['feature']} with importance: {most_important_feature['importance']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train with the two most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the two most important features\n",
    "top_2_features = importances['feature'].head(2).values\n",
    "X_train_top_2 = X_train[top_2_features]\n",
    "X_test_top_2 = X_test[top_2_features]\n",
    "\n",
    "# Train the model using these two features\n",
    "model.fit(X_train_top_2, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred_top_2 = model.predict(X_test_top_2)\n",
    "accuracy_top_2 = accuracy_score(y_pred_top_2, y_test)\n",
    "\n",
    "print(f\"Accuracy with the top 2 features: {accuracy_top_2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### two less important : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# two least important features\n",
    "bottom_2_features = importances['feature'].tail(2).values\n",
    "X_train_bottom_2 = X_train[bottom_2_features]\n",
    "X_test_bottom_2 = X_test[bottom_2_features]\n",
    "\n",
    "# Train the model using these\n",
    "model.fit(X_train_bottom_2, y_train)\n",
    "\n",
    "# Predict and evaluate accuracy\n",
    "y_pred_bottom_2 = model.predict(X_test_bottom_2)\n",
    "accuracy_bottom_2 = accuracy_score(y_pred_bottom_2, y_test)\n",
    "\n",
    "print(f\"Accuracy with the bottom 2 features: {accuracy_bottom_2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### as we can see, our top and bottom are not very reflective on the importance of them, as we got a better score for bottom rather than top features. we can ever do a cross validation to check :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_top_2 = X[top_2_features]\n",
    "cv_scores_top_2 = cross_val_score(model, X_top_2, y, cv=5)\n",
    "print(f\"Cross-validation scores with top 2 features: {cv_scores_top_2}\")\n",
    "print(f\"Mean CV score with top 2 features: {np.mean(cv_scores_top_2):.4f}\")\n",
    "\n",
    "X_bottom_2 = X[bottom_2_features]\n",
    "cv_scores_bottom_2 = cross_val_score(model, X_bottom_2, y, cv=5)\n",
    "print(f\"Cross-validation scores with bottom 2 features: {cv_scores_bottom_2}\")\n",
    "print(f\"Mean CV score with bottom 2 features: {np.mean(cv_scores_bottom_2):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### this might be due to overfitting, or also because the bottom data have at the end better pattern than the top data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thanks to statistical testing, we can prove, or unprove our result from above, saying that the top and bottom are not really relevant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### re-doing step 2, for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pingouin as pg\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load and clean dataset\n",
    "df = pd.read_csv(\"../Total air emissions by greenhouse gas.csv\")\n",
    "years = [str(year) for year in range(1990, 2024)]\n",
    "for year in years:\n",
    "    df[year] = pd.to_numeric(df[year], errors='coerce')\n",
    "df[years] = df[years].fillna(df[years].mean())\n",
    "\n",
    "df['growth'] = df['2023'] - df['1990']\n",
    "df['target'] = (df['growth'] > 0).astype(int)\n",
    "\n",
    "X = df[years]\n",
    "y = df['target']\n",
    "\n",
    "# Split and train model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, random_state=0)\n",
    "model = SVC(C=1.0, gamma=0.0001, kernel=\"rbf\")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Permutation importance\n",
    "pi = permutation_importance(model, X_test, y_test, n_repeats=50, random_state=0)\n",
    "importances = pd.DataFrame({'feature': X.columns, 'importance': pi['importances_mean']})\n",
    "importances = importances.sort_values(by='importance', ascending=False)\n",
    "\n",
    "# Select features\n",
    "top_2_features = importances['feature'].head(2).values\n",
    "bottom_2_features = importances['feature'].tail(2).values\n",
    "\n",
    "# Re-train models with top 2 and bottom 2 features\n",
    "model_top2 = SVC(C=1.0, gamma=0.0001, kernel=\"rbf\")\n",
    "model_bottom2 = SVC(C=1.0, gamma=0.0001, kernel=\"rbf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training again, for bottom2, top2, majority"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_top2 = X_train[top_2_features]\n",
    "X_test_top2 = X_test[top_2_features]\n",
    "X_train_bottom2 = X_train[bottom_2_features]\n",
    "X_test_bottom2 = X_test[bottom_2_features]\n",
    "\n",
    "model_top2.fit(X_train_top2, y_train)\n",
    "model_bottom2.fit(X_train_bottom2, y_train)\n",
    "\n",
    "y_pred_top2 = model_top2.predict(X_test_top2)\n",
    "y_pred_bottom2 = model_bottom2.predict(X_test_bottom2)\n",
    "\n",
    "model_majority = DummyClassifier(strategy=\"most_frequent\")\n",
    "model_majority.fit(X_train_top2, y_train)\n",
    "y_pred_majority = model_majority.predict(X_test_top2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### building a classifier correctness dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_eval = pd.DataFrame({\n",
    "    'top2': y_pred_top2 == y_test.values,\n",
    "    'bottom2': y_pred_bottom2 == y_test.values,\n",
    "    'majority': y_pred_majority == y_test.values\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performed McNemar test bettwen the top 2 and the bottom 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observed1, stats1 = pg.chi2_mcnemar(df_eval, x='bottom2', y='majority')\n",
    "print(\"McNemar's test between bottom2 and majority classifier:\")\n",
    "print(stats1)\n",
    "\n",
    "observed2, stats2 = pg.chi2_mcnemar(df_eval, x='top2', y='bottom2')\n",
    "print(\"McNemar's test between top2 and bottom2 classifier:\")\n",
    "print(stats2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking normality on original features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sub = df[years]\n",
    "normality = pg.normality(df_sub)\n",
    "print(\"Normality test results:\")\n",
    "print(normality)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bottom2 vs majority has a p of 0.4795, no real difference\n",
    "\n",
    "### top2 vs bottom2 has a p of 1, so no difference at all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correlation analysis (Pearson, since normality generally ok on large samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = pg.pairwise_corr(df_sub, method=\"pearson\")\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "### performing pca and converting the pca output into a df with the original data index (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)  # X : year 1990-2023 which are your features\n",
    "\n",
    "# converting the PCA output into a df with the original data index (optional)\n",
    "pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\n",
    "pca_df['target'] = y  # add target to the DataFrame for color-coding in the plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the 2D representation of the PCA-transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(pca_df['PC1'], pca_df['PC2'], c=pca_df['target'], cmap='viridis')\n",
    "plt.title('PCA - 2D Projection of the Data')\n",
    "plt.xlabel('Principal Component 1')\n",
    "plt.ylabel('Principal Component 2')\n",
    "plt.colorbar(label='Target (Growth > 0)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see outliers, some datapoint with unusual feature value. PC1 is capturing more variance than PC2. But the clusters are not very distincts. And PCA is not really helping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Function to run t-SNE and plot the results\n",
    "def run_tsne(X, y, random_state=0, perplexity=30):\n",
    "    tsne = TSNE(n_components=2, random_state=random_state, perplexity=perplexity)\n",
    "    X_tsne = tsne.fit_transform(X)\n",
    "\n",
    "    tsne_df = pd.DataFrame(X_tsne, columns=['TSNE1', 'TSNE2'])\n",
    "    tsne_df['target'] = y\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.scatter(tsne_df['TSNE1'], tsne_df['TSNE2'], c=tsne_df['target'], cmap='viridis')\n",
    "    plt.title(f't-SNE with random_state={random_state}, perplexity={perplexity}')\n",
    "    plt.xlabel('t-SNE Dimension 1')\n",
    "    plt.ylabel('t-SNE Dimension 2')\n",
    "    plt.colorbar(label='Target (Growth > 0)')\n",
    "    plt.show()\n",
    "\n",
    "# Run t-SNE with default parameters\n",
    "run_tsne(X, y)\n",
    "\n",
    "# Experiment with different values of perplexity and random_state\n",
    "for perplexity in [5, 10, 25, 50]:\n",
    "    run_tsne(X, y, random_state=42, perplexity=perplexity)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can see some clustering patterns in these t-SNE plots, which add more to the data than PCA, the two color are more separated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
