{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de3dbe1",
   "metadata": {},
   "source": [
    "*Prepared for the course \"TDPS22: Data Science Programming\" at Jönköping University, Teacher: [Marcel Bollmann](mailto:marcel.bollmann@ju.se)*\n",
    "\n",
    "# Exercise 1: Practice your Pandas skills!\n",
    "\n",
    "This notebook contains exercises on data exploration and transformation using the Pandas library.  It does **not** directly follow the book or user guide, but rather contains exercises that are practically motivated and require a wide variety of Pandas functionality.\n",
    "\n",
    "### Learning Goals\n",
    "\n",
    "- Understand how to think about data manipulation & analysis in Pandas.\n",
    "- Know how to use _indexing, smart indexing, and aggregations_ in Pandas.\n",
    "- Know how to use _grouping operations_ in Pandas.\n",
    "- Know how to _combine_ datasets in Pandas.\n",
    "\n",
    "Remember that you don't need to learn everything by heart; it's okay to need to look up things, but you should become more proficient in the basic principles & techniques needed to solve exercises like these.\n",
    "\n",
    "### Useful Resources\n",
    "\n",
    "- [_Python Data Science Handbook_ by Jake VanderPlas, Ch.3: Data Manipulation with Pandas](https://jakevdp.github.io/PythonDataScienceHandbook/index.html#3.-Data-Manipulation-with-Pandas)\n",
    "- [Pandas User Guide](https://pandas.pydata.org/docs/user_guide/)\n",
    "\n",
    "The datasets used here contain _synthetically generated_ (i.e., fake) data which is based on, but not identical to, the [\"Coffee Chain\" dataset from Kaggle](https://www.kaggle.com/datasets/qusaybtoush1990/coffee-chain).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60a64316",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext rich\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086c7ae6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ddate</th>\n",
       "      <th>Market</th>\n",
       "      <th>Product</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9/1/13</td>\n",
       "      <td>Central</td>\n",
       "      <td>Decaf Irish Cream</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>90</td>\n",
       "      <td>36</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5/1/12</td>\n",
       "      <td>East</td>\n",
       "      <td>Decaf Espresso</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>203</td>\n",
       "      <td>56</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1/1/13</td>\n",
       "      <td>West</td>\n",
       "      <td>Caffe Latte</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>524</td>\n",
       "      <td>136</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8/1/12</td>\n",
       "      <td>West</td>\n",
       "      <td>Earl Grey</td>\n",
       "      <td>Tea</td>\n",
       "      <td>273</td>\n",
       "      <td>81</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/1/13</td>\n",
       "      <td>West</td>\n",
       "      <td>Amaretto</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>201</td>\n",
       "      <td>-3</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2/1/12</td>\n",
       "      <td>Central</td>\n",
       "      <td>Darjeeling</td>\n",
       "      <td>Tea</td>\n",
       "      <td>185</td>\n",
       "      <td>59</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>3/1/12</td>\n",
       "      <td>East</td>\n",
       "      <td>Darjeeling</td>\n",
       "      <td>Tea</td>\n",
       "      <td>88</td>\n",
       "      <td>17</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>8/1/13</td>\n",
       "      <td>Central</td>\n",
       "      <td>Chamomile</td>\n",
       "      <td>Herbal Tea</td>\n",
       "      <td>61</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>4/1/12</td>\n",
       "      <td>East</td>\n",
       "      <td>Caffe Mocha</td>\n",
       "      <td>Espresso</td>\n",
       "      <td>124</td>\n",
       "      <td>38</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>5/1/12</td>\n",
       "      <td>West</td>\n",
       "      <td>Darjeeling</td>\n",
       "      <td>Tea</td>\n",
       "      <td>524</td>\n",
       "      <td>150</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 7 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data into a Pandas DataFrame\n",
    "data = \"data/coffee-chain.csv\"\n",
    "df = pd.read_csv(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbaa2fa4",
   "metadata": {},
   "source": [
    "- - - \n",
    "## Data Exploration\n",
    "\n",
    "Here are some common questions that you might want to explore on a dataset like this. They all have in common that they ***can be solved with just one line of code*** in Pandas. That doesn't mean they're trivial – they require you to understand how Pandas works and how you can think about data selection and transformation in Pandas. Sometimes there are also several different ways to achieve the same result. If you can implement a solution that needs more than one line of code, that's also fine – but I'd encourage you to try to find the one-line solution as well, simply in order to learn more about the possibilities that Pandas offers.\n",
    "\n",
    "If you're lost, don't forget you can reference the [book](https://jakevdp.github.io/PythonDataScienceHandbook/index.html#3.-Data-Manipulation-with-Pandas) or the [user guide](https://pandas.pydata.org/docs/user_guide/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e01792",
   "metadata": {},
   "source": [
    "**1. Does the dataset have any missing values?** Write an expression to obtain a _single boolean value_ (i.e., True or False) that signifies whether the DataFrame has any missing values or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3ce0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a69f34",
   "metadata": {},
   "source": [
    "**2. What different _product types_ are there in the dataset?** Produce a list of all unique product types in the dataset, i.e., unique values in the \"Product Type\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fa83693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d1c0fa",
   "metadata": {},
   "source": [
    "**3. What different _\"coffee\" products_ are there in the dataset?** Produce a list of all unique coffee products in the dataset, i.e., values in the \"Product\" column where the \"Product Type\" is \"Coffee\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0c4042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20aa6d7",
   "metadata": {},
   "source": [
    "**4. What different _\"coffee or espresso\" products_ are there in the dataset?** Do the same as above, but this time include all products where the \"Product Type\" is either \"Coffee\" or \"Espresso\". Try to figure out how to do this in a single Pandas expression — i.e., how can you select all rows in the dataset that match the required condition?\n",
    "\n",
    "_Hint:_ You might want to consult [\"Indexing and Selecting Data\" in the user guide](https://pandas.pydata.org/docs/user_guide/indexing.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fe6122b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0651949",
   "metadata": {},
   "source": [
    "**5. Which product type generates the most/the least profit, on average?** Find out the average \"Profit\" values by \"Product Type\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e196a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f573c396",
   "metadata": {},
   "source": [
    "**6. What's the _distribution_ of profits among all products?** Produce a table that has unique \"Product\" values (e.g., Amaretto, Caffe Latte, ...) as _rows_, and statistics about the distribution of their \"Profit\" values (e.g., count, mean, min, max, ...) as _columns_.\n",
    "\n",
    "_Hint:_ The statistics about distributions can be obtained with the `.describe()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82448465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c66bd1",
   "metadata": {},
   "source": [
    "**7. What are the average profits by products _and_ market region?** From the solution to the previous question, we know the mean \"Profit\" values for each \"Product\" in the dataset. Now, we want to look at the average profit by _two_ variables: \"Product\" and \"Market\". Produce a table that has products as _rows_, markets as _columns_, and the mean profits of the product–market combination as _values_.\n",
    "\n",
    "_Hint:_ This is a classic use case for [pivot tables](https://jakevdp.github.io/PythonDataScienceHandbook/03.09-pivot-tables.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "447cfeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30fdb6",
   "metadata": {},
   "source": [
    "**8. How many instances are there in the dataset of each product–market combination?** If you produced the pivot table for the previous question, you should see that several values in the table are \"NaN\" (_not a number_). It looks like some combinations of \"Product\" and \"Market\" might not exist in the dataset at all. Modify the pivot table from Q7 so that instead of averages, it shows _counts_ (i.e., how many values there are in total), and instead of \"NaN\" it fills in `0` for the missing combinations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72b45ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62806a7f",
   "metadata": {},
   "source": [
    "- - - \n",
    "## Data Preprocessing\n",
    "\n",
    "So far we just looked at the data in different ways, now we're going to modify it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6704b8ba",
   "metadata": {},
   "source": [
    "**9. Filter out all products where we don't have data from all markets.** In Q8, we saw that some product–market combinations don't appear in the dataset at all. Maybe we want to do an analysis based on products and market regions, and therefore only want to keep products where we have data from _all_ of the four markets. In other words, we want to drop all the products where one of the markets has a count of `0`. Make a new DataFrame `df_subset` that consists of only the rows in `df` which fulfill this criterion.\n",
    "\n",
    "_Hint:_ This is possible to implement in one line, but it might easier to think about if you define a \"helper function\" first. This helper function should take a Pandas data structure and return `True` if it contains data from four different markets, and `False` otherwise. Afterwards, you can use this helper function to _filter_ the dataset.\n",
    "\n",
    "_Hint 2:_ If you implemented the filtering correctly, the resulting `df_subset` should have exactly 2616 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e3edb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = ...  # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0601a9c9",
   "metadata": {},
   "source": [
    "_Check:_ If you created the column correctly, the following line of code should evaluate to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af047387",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_subset) == 7426"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c634cc2",
   "metadata": {},
   "source": [
    "**10. Make a new column \"Profit Above Average\" that is `True` when the \"Profit\" is above the average of the dataset, and `False` otherwise.** Creating new columns can be a useful preprocessing step for further analyses or visualizations. Work with the original `df` here, select all rows where \"Profit\" is above average, and assign the result to the new column \"Profit Above Average\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b0ecb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Profit Above Average\"] = ...  # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564b81e7",
   "metadata": {},
   "source": [
    "_Check:_ If you created the column correctly, the following line of code should evaluate to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebd770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Profit Above Average\"].sum() == 3401"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df347bad",
   "metadata": {},
   "source": [
    "**11. Transform the `Ddate` column into a `datetime` type.** The dataset contains a column `Ddate` which stores a date in month-day-year format. However, it's currently just stored as a string. In order to perform operations based on this date column (for example, grouping or filtering by month), it would be helpful to convert it to a proper Python `datetime` expression. _Transform_ the `Ddate` column from `string` into a `datetime` format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5d705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c067f5d",
   "metadata": {},
   "source": [
    "_Check:_ If you transformed the column correctly, the following line of code should work and return `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548ea2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(df[\"Ddate\"].apply(lambda x: x.month).unique()) == list(range(1, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc899203",
   "metadata": {},
   "source": [
    "**12. Perform min-max scaling on the `Expenses` column.** Some machine learning algorithms are sensitive to the absolute distance between data points. It's therefore sometimes necessary to _reshape_ your data. Here, we want to perform min-max scaling on a column, which means _transforming_ our data to fall within the $[0,1]$ range. In mathematical terms, this means applying the function:\n",
    "\n",
    "$$\n",
    "f(x) = \\frac{x - \\min (x)}{\\max (x) - \\min (x)}\n",
    "$$\n",
    "\n",
    "Perform this transformation on the `Expenses` column.\n",
    "\n",
    "_Hint:_ Don't try to do this one on one line; you probably want to write a helper function here for clarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04d758a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c77495",
   "metadata": {},
   "source": [
    "_Check:_ If you transformed the column correctly, the following line of code should evaluate to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efcd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Expenses\"].aggregate([min, max]).tolist() == [0.0, 1.0] and (\n",
    "    0.19 < df[\"Expenses\"].median() < 0.21\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82fb310",
   "metadata": {},
   "source": [
    "- - - \n",
    "## Combining Datasets\n",
    "\n",
    "The dataset we looked at contains data for the years 2012 and 2013. Let's assume we're getting additional data for the years 2014/2015 later, and want to merge these with the first dataset.  Since we modified the original dataset a lot in the exercises above, let's first reload it here, and then load the new \"extra\" dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cafd1153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ddate</th>\n",
       "      <th>Market</th>\n",
       "      <th>Product</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Profit</th>\n",
       "      <th>Expenses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5/1/15</td>\n",
       "      <td>South</td>\n",
       "      <td>Caffe Mocha</td>\n",
       "      <td>231</td>\n",
       "      <td>67</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2/1/15</td>\n",
       "      <td>Central</td>\n",
       "      <td>Decaf Irish Cream</td>\n",
       "      <td>319</td>\n",
       "      <td>136</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7/1/14</td>\n",
       "      <td>Central</td>\n",
       "      <td>Darjeeling</td>\n",
       "      <td>251</td>\n",
       "      <td>133</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5/1/14</td>\n",
       "      <td>East</td>\n",
       "      <td>Decaf Espresso</td>\n",
       "      <td>194</td>\n",
       "      <td>142</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/1/14</td>\n",
       "      <td>Central</td>\n",
       "      <td>Decaf Irish Cream</td>\n",
       "      <td>192</td>\n",
       "      <td>103</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4/1/14</td>\n",
       "      <td>East</td>\n",
       "      <td>Lemon</td>\n",
       "      <td>77</td>\n",
       "      <td>-8</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>5/1/14</td>\n",
       "      <td>West</td>\n",
       "      <td>Decaf Espresso</td>\n",
       "      <td>105</td>\n",
       "      <td>41</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>2/1/14</td>\n",
       "      <td>West</td>\n",
       "      <td>Caffe Mocha</td>\n",
       "      <td>116</td>\n",
       "      <td>-34</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>2/1/14</td>\n",
       "      <td>Central</td>\n",
       "      <td>Decaf Irish Cream</td>\n",
       "      <td>119</td>\n",
       "      <td>36</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>9/1/15</td>\n",
       "      <td>West</td>\n",
       "      <td>Lemon</td>\n",
       "      <td>144</td>\n",
       "      <td>28</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data)\n",
    "df_extra = pd.read_csv(\"data/coffee-chain-extra.csv\")\n",
    "df_extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f98530",
   "metadata": {},
   "source": [
    "**13. Concatenate the two datasets `df` and `df_extra` into a DataFrame `df_new`,** making sure that the new, concatenated dataset **has no duplicate indices.** The result should be a DataFrame with 15,000 rows that has a numerical index (like our original datasets) from 0 to 14,999."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a861d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = ...  # Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfad60f6",
   "metadata": {},
   "source": [
    "_Check:_ If you created the DataFrame correctly, the following should evaluate to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(df_new) == 15000) and (14999 in df_new.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bd83e9",
   "metadata": {},
   "source": [
    "- - -\n",
    "\n",
    "Sometimes, we want to combine two datasets that have complementary information, i.e., different columns. For example, let's say we have this tiny dataset containing additional information about \"Market Size\" for each of our four markets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c50a180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Market</th>\n",
       "      <th>Market Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Central</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>East</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>West</td>\n",
       "      <td>Major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South</td>\n",
       "      <td>Minor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_markets = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        \"Market\": [\"Central\", \"East\", \"West\", \"South\"],\n",
    "        \"Market Size\": [\"Major\", \"Major\", \"Major\", \"Minor\"],\n",
    "    }\n",
    ")\n",
    "df_markets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4176b7",
   "metadata": {},
   "source": [
    "**14. Merge `df_new` with `df_markets`.** The resulting DataFrame should look just like `df_new`, but have an extra column \"Market Size\" whose value depends on the \"Market\" value of the given row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b293109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e364f77f",
   "metadata": {},
   "source": [
    "**15. Fill in missing data in the `Product Type` column.** You might have noticed that the `df_extra` dataset we loaded above is missing a column that the original `df` had: the \"Product Type\"!  Luckily, this information can be easily recovered, as the \"Product Type\" can be uniquely deduced from the \"Product\" (e.g., a \"Darjeeling\" product is always a \"Tea\"). However, the process to get there may be a little bit tricky.\n",
    "\n",
    "_Hint:_ First, try to get a DataFrame that has all unique `(Product, Product Type)` combinations. Then, you should be able to merge this with `df_extra`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6961447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe9a37",
   "metadata": {},
   "source": [
    "- - - \n",
    "## Slightly harder bonus challenges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f727ac",
   "metadata": {},
   "source": [
    "**16. Make a new column \"Top within Product\" that is `True` when the \"Profit\" is within the top 25% of its \"Product\" category.**\n",
    "\n",
    "_Hints:_\n",
    "\n",
    "1. Find the cutoff value for the top 25% in each \"Product\" category, and store this in a variable. (A keyword to look out for when obtaining the \"top 25%\" is _quantiles_...)\n",
    "2. Write a function that takes a Pandas Series and returns `True` if its \"Profit\" value is higher than the cutoff value for its \"Product\" category.\n",
    "3. [Apply](https://pandas.pydata.org/docs/user_guide/basics.html#row-or-column-wise-function-application) this function to each row of `df` to get your new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ef15da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814cb69d",
   "metadata": {},
   "source": [
    "_Check:_ If you created the column correctly, the following line of code should evaluate to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e46ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Top within Product\"].sum() == 2518"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad5a382",
   "metadata": {},
   "source": [
    "**17. Try to do the same as in Q15, but with `df_new`.** In other words, try to fill in the `NaN` values in the \"Product Type\" after you have already merged `df` and `df_extra` together. This can be quite tricky, and there are many possible ways to approach this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a8260d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-dsp",
   "language": "python",
   "name": "python3-dsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
